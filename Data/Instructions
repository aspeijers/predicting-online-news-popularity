The following document has the accuracy values for all the models we trained and tested along the process. For each group of tests (where we just tuned one parameter at a time) we give ** to the best result and for each different matrix of features we get *** to the best model in terms of accuracy over all the different tested combinations.

The models we have executed are as follows:

GBM:

The values inside the brackets are respectively (ntrees, max_depth, min_rows, learn_rate) 


Manually selected features matrix:

(500, 5, 10, 0.01) -> 0.5221
(230, 5, 10, 0.01) -> 0.5207
(240, 5, 10, 0.01) -> 0.5219
(250, 5, 10, 0.01) -> 0.523
(265, 5, 10, 0.01) -> 0.5226
(280, 5, 10, 0.01) -> 0.5231***
(300, 5, 10, 0.01) -> 0.5225

(280, 15, 10, 0.01) -> 0.5057
(280, 3, 10, 0.01) -> 0.5163
(280, 4, 10, 0.01) -> 0.5182
(280, 7, 10, 0.01) -> 0.5239
(280, 6, 10, 0.01) -> 0.5252**

(280, 6, 5, 0.01) -> 0.5213
(280, 6, 8, 0.01) -> 0.5213
(280, 6, 12, 0.01) -> 0.5236
(280, 6, 20, 0.01) -> 0.5244**

(280, 6, 10, 0.001) -> 0.5053
(280, 6, 10, 0.005) -> 0.5181
(280, 6, 10, 0.05) -> 0.5117
(280, 6, 10, 0.0001) -> 0.4969
(280, 6, 10, 0.02) -> 0.5206**

(257, 6, 20, 0.01) -> 0.525
(285, 6, 20, 0.01) -> 0.5257***
(290, 6, 20, 0.01) -> 0.5257
(295, 6, 20, 0.01) -> 0.5253



Matrix of 49 features:

(500, 5, 10, 0.01) -> 0.5276
(230, 5, 10, 0.01) -> 0.5242
(600, 5, 10, 0.01) -> 0.528
(700, 5, 10, 0.01) -> 0.5268
(650, 5, 10, 0.01) -> 0.5281
(550, 5, 10, 0.01) -> 0.5276
(625, 5, 10, 0.01) -> 0.5282**
(675, 5, 10, 0.01) -> 0.5277

(625, 4, 10, 0.01) -> 0.5232
(625, 6, 10, 0.01) -> 0.5286**
(625, 7, 10, 0.01) -> 0.5268
(625, 8, 10, 0.01) -> 0.5201

(625, 6, 5, 0.01) -> 0.5264
(625, 6, 8, 0.01) -> 0.5274
(625, 6, 12, 0.01) -> 0.5284**
(625, 6, 11, 0.01) -> 0.5276

(625, 6, 10, 0.001) -> 0.5178
(625, 6, 10, 0.005) -> 0.5263**
(625, 6, 10, 0.05) -> 0.5168
(625, 6, 10, 0.0001) -> 0.5159
(625, 6, 10, 0.02) -> 0.5263**

(625, 6, 13, 0.015) -> 0.5273
(625, 6, 13, 0.01) -> 0.5287
(625, 6, 14, 0.01) -> 0.5302**
(625, 6, 15, 0.01) -> 0.5297

(630, 6, 15, 0.01) -> 0.5292
(640, 6, 15, 0.01) -> 0.5293
(645, 6, 15, 0.01) -> 0.5289
(620, 6, 15, 0.01) -> 0.5296**
(623, 6, 15, 0.01) -> 0.5296

(630, 6, 14, 0.01) -> 0.5301
(640, 6, 14, 0.01) -> 0.5297
(628, 6, 14, 0.01) -> 0.5299
(620, 6, 14, 0.01) -> 0.5297
(626, 6, 14, 0.01) -> 0.5303***

(626, 7, 14, 0.01) -> 0.5284
(626, 6, 14, 0.015) -> 0.5253
(626, 6, 14, 0.007) -> 0.5252



Matrix of 50 features:

(500, 5, 10, 0.01) -> 0.5253
(400, 5, 10, 0.01) -> 0.5253
(450, 5, 10, 0.01) -> 0.5246
(350, 5, 10, 0.01) -> 0.5267***
(300, 5, 10, 0.01) -> 0.5252
(375, 5, 10, 0.01) -> 0.5259
(365, 5, 10, 0.01) -> 0.5264
(325, 5, 10, 0.01) -> 0.5251
(550, 5, 10, 0.01) -> 0.524
(600, 5, 10, 0.01) -> 0.5257
(650, 5, 10, 0.01) -> 0.5251

(350, 6, 10, 0.01) -> 0.5244**
(350, 7, 10, 0.01) -> 0.5218
(350, 4, 10, 0.01) -> 0.522
(350, 3, 10, 0.01) -> 0.5198
(350, 9, 10, 0.01) -> 0.5228

(350, 5, 5, 0.01) -> 0.5238
(350, 5, 8, 0.01) -> 0.5259
(350, 5, 12, 0.01) -> 0.5262
(350, 5, 14, 0.01) -> 0.5276**

(350, 5, 14, 0.02) -> 0.5282
(350, 5, 14, 0.025) -> 0.5283***
(350, 5, 14, 0.005) -> 0.5183
(350, 5, 14, 0.001) -> 0.5063



Random Forest:

Tunning parameters for the RF 50 features matrix

ntrees, max_depth, nfolds, mtries, balance_class=FALSE

Matrix of 50 features:

(500, 5, 5) -> 0.5038
(500, 6, 5, 15) -> 0.5093
(500, 5, 5, 20) -> 0.5101
(500, 5, 5, 25) -> 0.5
(500, 5, 5, 30) -> 0.5083