# compute probability of new variable being in model
prob <- marg.lik.1 * model.prior[d.1+1] / (marg.lik.1 * model.prior[d.1+1] + marg.lik.0 * model.prior[d.0+1])
# update gamma and variables
if (runif(1) < prob) {
gamma[j] <- 1
}
else {
gamma[j] <- 0
}
}
#Compute results for the new model
d.new <- sum(gamma!=0)
PHI.new <- PHI[,c(TRUE,(gamma==1))]
H.mle.new <- PHI.new%*%solve(t(PHI.new)%*%PHI.new)%*%t(PHI.new)
e.new <- (diag(n)-H.mle.new) %*% y
R.sq.new <- as.numeric( 1 - (t(e.new) %*% e.new) / sum((y - mean(y))^2) )
marg.lik.new <- as.numeric(factorial((n-1)/2 - 1) / (pi^((n-1)/2) * sqrt(n)) * (sqrt(t(e) %*% e))^(1-n) * (1+g)^((n-d.new-2)/2) / (1+g*(1-R.sq.new))^((n-1)/2) )
#Save w estimates (w computed based on the w_bayes estimate expression for Zellner's g prior)
w.history[i,which(gamma!=0)] = ((g/ (g+1)) * solve(t(PHI.new)%*% PHI.new)%*%t(PHI.new)%*%y)[-1]
#Save probabilities
prob.new <- marg.lik.new * model.prior[d.new+1]
prob.history[i] <- marg.lik.new
#Save gamma
gamma.history[i,] <- gamma
}
no.vars <- rowSums(gamma.history)
plot(1:L, no.vars, type="l",xlab="Iteration", ylab="Number of variables in the model", main="Model size")
abline(mean(no.vars), 0, col="red")
library(plyr)
model.prob = data.frame( model = apply( gamma.history,1, function(x) {paste(c(1:50)[as.logical(x)], collapse = ", ")}  ))
model.prob = ddply(model.prob, .(model), nrow)
model.prob$prob = model.prob$V1/L
model.prob = model.prob[order(model.prob$V1, decreasing =T),]
model.prob[1:5,c(1,3)]
cummean <- matrix(NA, L, m)
for (i in 1:L) {
cummean[i,] <- colSums(gamma.history[1:i,,drop=F])/i
}
matplot(1:L, cummean, type="l", lty=1, xlab="Step", ylab="marginal inclusion probability", main="Marginal Inclusion Probabilities for each of the 50 Features", las=1)
plot(cummean[1000,1:40], xlim=c(0,50), ylim=c(0,1), xlab="Predictor", ylab="Posterior probability of non-zero coefficient", main="Marginal Inclusion Probabilities")
points(41:45, cummean[1000, 41:45], col="blue")
points(46:50, cummean[1000, 46:50], col="red")
abline(1, 0, col="red")
abline(0.5, 0, col="blue")
w.history[is.na(w.history)] <- 0
plot(colMeans(w.history, na.rm = TRUE)[1:40], xlim=c(0,50), ylim=c(-0.5, 1.5), xlab="Predictor", ylab="Expected posterior coefficients", main="Bayesian Model Averaging - Estimates of Coefficients")
points(41:45, colMeans(w.history, na.rm = TRUE)[41:45], col="blue")
points(46:50, colMeans(w.history, na.rm = TRUE)[46:50], col="red")
abline(1, 0, col="red")
abline(0.5, 0, col="blue")
library(shiny)
install.packages("shiny")
library(shiny)
library(mtvnorm)
library(mvtnorm)
x <- rmvnorm(100, mean=c(1,5), sigma=1*diag(2))
plot(x[,1], x[,2])
rho <- 0.8
sdx1 <- 2
sdx2 <- 2
covTerm <- rho * sdx1 * sdx2
matrix(c(sdx1^2,covTerm, covTerm, sdx2^2), ncol=2)
x <- rmvnorm(100, mean=c(1,5), sigma=cvc)
plot(x[,1], x[,2])
cvc <- matrix(c(sdx1^2,covTerm, covTerm, sdx2^2), ncol=2)
x <- rmvnorm(100, mean=c(1,5), sigma=cvc)
plot(x[,1], x[,2])
library(devtools)
install_github( "aspeijers/predicting-online-news-popularity/hamclass")
install_github( "aspeijers/predicting-online-news-popularity/hamclass", auth_token = "e5fc4b5f96694b436e1f183884722398d98f9764" )
?hamclass
load("~/Desktop/BGSE/AdvancedCompMethods/Project/predicting-online-news-popularity/Code/randomForest.R")
?points
pi
?lines
?points
?axis
?points
if (!require("knitr")) install.packages("knitr"); library(knitr)
if (!require("rmarkdown")) install.packages("rmarkdown"); library(rmarkdown)
opts_chunk$set(comment='##', warning=FALSE, message=FALSE, include=TRUE, echo=TRUE, cache=TRUE, cache.comments=FALSE)
output <- opts_knit$get("rmarkdown.pandoc.to")
if (output=="html") opts_chunk$set(fig.width=10, fig.height=5)
if (output=="latex") opts_chunk$set(fig.width=6,  fig.height=4, dev = 'cairo_pdf', dev.args=list(family="Arial"))
genEasy <- function(noObs = 100) {
noFeatures <- 10
X <- matrix(runif(noObs*noFeatures), ncol = noFeatures)
y <- ifelse(X[,1] > 0.5, 1, 0)
return(list(X=X, y=y))
}
genDifficult <- function(noObs = 100) {
noFeatures <- 10
X <- matrix(runif(noObs*noFeatures), ncol = noFeatures)
y <- ifelse(sign((X[,1]-0.5)*(X[,2]-0.5)*(X[,3]-0.5)) > 0, 1, 0)
return(list(X=X, y=y))
}
if (!require("doMC")) install.packages("doMC")
if (!require("class")) install.packages("class")
if (!require("dplyr")) install.packages("dplyr")
if (!require("ggplot2")) install.packages("ggplot2")
trainEasy <- genEasy(100)
testEasy <- genEasy(1000)
trainDiff <- genDifficult(100)
testDiff <- genDifficult(1000)
ks <- c(1:60)
getResubError <- function(features, labels, k) {
pred <- knn(train = features, test = features, cl = labels, k = k)
return(c(k = k, error = mean(pred != labels)))
}
registerDoMC(detectCores())
install.packages("doMC")
library(doMC)
registerDoMC(detectCores())
resubError <- foreach(k = ks,
.combine = rbind,
.packages = c("class", "dplyr")) %dopar% {
# some helpful debugging messages
#cat("The current test set! k=", k, "\n")
# kNN results
resEasy <- getResubError(trainEasy$X, trainEasy$y, k)
resDiff <- getResubError(trainDiff$X, trainDiff$y, k)
# final output
data.frame(c("Resub", "Resub"), c("Easy", "Difficult"),
rbind(resEasy, resDiff))
}
colnames(resubError) <- c("cvType", "exp", "k", "Error")
resubError <- cbind(resubError, SE=NA)
genCVid <- function(noObs = 100, K = 10, seed = round(runif(1)*10000, 0)) {
stopifnot(noObs >= K); set.seed(seed)
CVindex <- rep(1:K, times = ceiling(noObs / K))[1:noObs]
CVindexRand <- sample(CVindex, noObs)
}
getKfoldError <- function(features, labels, k, bucket) {
pred <- knn(train = features[cvID!=bucket,],
test = features[cvID==bucket,],
cl = labels[cvID!=bucket],
k = k)
error <- mean(pred != labels[cvID==bucket])
return(c(k = k, bucket = bucket, error = error))
}
noBuckets <- nrow(trainEasy$X)
cvID <- genCVid(noBuckets, noBuckets, 1111)
looError <- foreach(bucket = rep(1:noBuckets, length(ks)),
k = rep(ks, each=noBuckets),
.combine = rbind,
.packages = c("class", "dplyr")) %dopar% {
# some helpful debugging messages
#cat("Bucket", bucket, "is the current test set! k=", k, "\n")
# kNN results
resEasy <- getKfoldError(trainEasy$X, trainEasy$y, k, bucket)
resDiff <- getKfoldError(trainDiff$X, trainDiff$y, k, bucket)
# final output
data.frame(c("Loo", "Loo"), c("Easy", "Difficult"),
rbind(resEasy, resDiff))
}
colnames(looError) <- c("cvType", "exp", "k", "bucket", "error")
looError <- as.data.frame(looError) %>%
group_by(cvType, exp, k) %>%
summarize(Error = mean(error),
SE = sd(error)/mean(n()))
noBuckets <- 10
cvID <- genCVid(nrow(trainEasy$X), noBuckets, 1111)
kfoldError <- foreach(bucket = rep(1:noBuckets, length(ks)),
k = rep(ks, each=noBuckets),
.combine = rbind,
.packages = c("class", "dplyr")) %dopar% {
# some helpful debugging messages
#cat("Bucket", bucket, "is the current test set! k=", k, "\n")
# kNN results
resEasy <- getKfoldError(trainEasy$X, trainEasy$y, k, bucket)
resDiff <- getKfoldError(trainDiff$X, trainDiff$y, k, bucket)
# final output
data.frame(c("10fold", "10fold"), c("Easy", "Difficult"),
rbind(resEasy, resDiff))
}
colnames(kfoldError) <- c("cvType", "exp", "k", "bucket", "error")
kfoldError <- kfoldError %>%
group_by(cvType, exp, k) %>%
summarize(Error = mean(error),
SE = sd(error)/mean(n()))
noMC <- nrow(trainEasy$X)
noBuckets <- noMC/10
mcError <- foreach(bucket = rep(1:noBuckets, length(ks)*noMC/10),
k = rep(ks, each=noMC),
.combine = rbind,
.packages = c("class", "dplyr")) %dopar% {
# some helpful debugging messages
#cat("Bucket", bucket, "is the current test set! k=", k, "\n")
# randomly subsetting in each iteration
cvID <- genCVid(nrow(trainEasy$X), noBuckets)
# kNN results
resEasy <- getKfoldError(trainEasy$X, trainEasy$y, k, bucket)
resDiff <- getKfoldError(trainDiff$X, trainDiff$y, k, bucket)
# final output
data.frame(c("MC", "MC"), c("Easy", "Difficult"),
rbind(resEasy, resDiff))
}
colnames(mcError) <- c("cvType", "exp", "k", "bucket", "error")
mcError <- mcError %>%
group_by(cvType, exp, k) %>%
summarize(Error = mean(error),
SE = sd(error)/mean(n()))
getBIC <- function(features, labels, k) {
pred <- knn(train = features, test = features, cl = labels, k = k,
prob = TRUE)
noObs <- length(labels)
bic <- -2*sum(log(attr(pred, "prob"))) + (noObs/k)*log(noObs)
return(c(k = k, error = bic))
}
bicScore <- foreach(k = ks,
.combine = rbind,
.packages = c("class", "dplyr")) %dopar% {
# some helpful debugging messages
#cat("The current test set! k=", k, "\n")
# kNN results
resEasy <- getBIC(trainEasy$X, trainEasy$y, k)
resDiff <- getBIC(trainDiff$X, trainDiff$y, k)
# final output
data.frame(c("BIC", "BIC"), c("Easy", "Difficult"),
rbind(resEasy, resDiff))
}
colnames(bicScore) <- c("cvType", "exp", "k", "Error")
bicScore <- cbind(bicScore, SE=NA)
# so that we can illustrate it together with CV errors on the same figure
er <- bicScore$Error
bicScore$Error <- (er-min(er))/(max(er)- min(er))
getTestError <- function(features, labels, k, testFeatures, testLabels) {
pred <- knn(train = features, test = testFeatures, cl = labels, k = k)
return(c(k = k, error = mean(pred != testLabels)))
}
testError <- foreach(k = ks,
.combine = rbind,
.packages = c("class", "dplyr")) %dopar% {
# some helpful debugging messages
#cat("The current test set! k=", k, "\n")
# kNN results
resEasy <- getTestError(trainEasy$X, trainEasy$y, k,
testEasy$X, testEasy$y)
resDiff <- getTestError(trainDiff$X, trainDiff$y, k,
testDiff$X, testDiff$y)
# final output
data.frame(c("Test", "Test"), c("Easy", "Difficult"),
rbind(resEasy, resDiff))
}
registerDoSEQ()
colnames(testError) <- c("cvType", "exp", "k", "Error")
testError <- cbind(testError, SE=NA)
results <- rbind(resubError, looError, kfoldError,
mcError, bicScore, testError)
ggplot(data = results,
aes(x = factor(k), y = Error, colour=cvType, group=cvType)) +
geom_line() +
geom_point() +
facet_wrap(~exp, ncol=1) +
scale_x_discrete("k -Number of nearest neighbors",
breaks = c(1, seq(5,60,5))) +
ylab("Misclassification error") +
theme_bw(base_size = 14, base_family = "Helvetica")
findThreshold <- function(x, y) {
noPoints <- length(x)
errors <- rep(NA, noPoints-1)
thresholds <- rep(NA, noPoints-1)
splitLabels <- matrix(NA, ncol=2, nrow=noPoints-1)
# we go sequentially over each point and cut between that point and the
# closest neighbor
for (idx in 1:(noPoints-1)) {
# locate a potential threshold, a split between two points
potThres <- mean(x[idx:(idx+1)])
# check the classification error, when both sides,
# are classified with mean label
predictedClasses <- rep(NA, noPoints)
meanLeft <- mean(y[x < potThres])
meanRight <- mean(y[x >= potThres])
if (meanLeft < 0.5) {
predictedClasses[x < potThres] <- 0
} else {
predictedClasses[x < potThres] <- 1
}
if (meanRight < 0.5) {
predictedClasses[x > potThres] <- 0
} else {
predictedClasses[x > potThres] <- 1
}
# error of this split
misError <- mean(predictedClasses != y)
# recording the accuracy, thresholds and labels of
# the splitted interval
errors[idx] <- misError
thresholds[idx] <- potThres
splitLabels[idx,] <- c(predictedClasses[x < potThres][1],
predictedClasses[x > potThres][1])
}
# print(cbind(errors, thresholds, splitLabels))
# next we find the minimum and the best threshold
minError <- min(errors)
bestThreshold <- thresholds[which(errors==minError)]
# if more than 1 threshold has the same accuracy we choose one randomly
bestThreshold <- sample(bestThreshold, 1)
# what are the final labels of the best split?
labels <- splitLabels[which(thresholds==bestThreshold),]
# print(cbind(minError, bestThreshold, labels))
return(list(thres = bestThreshold,
err = minError,
labels = labels))
}
?cut
aaa <- seq(0,10,.1)
aaa <- seq(0, 10, 1)
aaa
cut(aaa, c(0,1), include.lowest = TRUE)
Z <- stats::rnorm(10000)
table(cut(Z, breaks = -6:6))
aaa <- cut(Z, breaks= -6:6)
aaa
Z <- stats::rnorm(1000)
aaa <- cut(Z, breaks= -6:6)
aaa
table(cut(Z, breaks = -6:6))
table(cut(Z, breaks = -6:6, include.lowest = ))
table(cut(Z, c(0,1), include.lowest = ))
Z
?append
head(trainEasy)
head(trainDiff)
load("~/Desktop/BGSE/AdvancedCompMethods/Project/predicting-online-news-popularity/Code/randomForest_workspace.RDataTmp")
load("~/Desktop/BGSE/AdvancedCompMethods/Project/predicting-online-news-popularity/Code/randomForest_workspace.RDataTmp")
load("~/Desktop/BGSE/AdvancedCompMethods/Project/predicting-online-news-popularity/Code/randomForest_workspace.RData")
load("~/Desktop/BGSE/AdvancedCompMethods/Problemset Info/PS6_workspace.RData")
load("~/Desktop/BGSE/Financial Econs/PS5/PS5_workspace.RData")
library(randomForest)
library(forecast)
library(gbm)
forecast.data <- read.csv("~/Documents/Semester_2/Financial Econometrics/forecast-competition-data.csv")
onestp <- function(y){
require(forecast)
coln = c(1,4,5,11,13,16,21,24,27,28,35,38,40,41,46)
nrow = nrow(y)
y = y[,coln]
t = y[-1,1]
xreg = scale(y[,-1])
n = 3
order = matrix(c(0:(n-1),rep(0,n),rep(0,n)),nrow= n)
model <- apply(order,1,function(x) arima(t,xreg = xreg[-nrow,],order = x))
newxreg = matrix(xreg[nrow,],ncol=ncol(xreg))
onestep.for <- vapply(model,function(x) as.numeric(predict(x,
newxreg = newxreg,n.ahead = 1)$pred),FUN.VALUE = 0)
print(unlist(onestep.for))
pred <- mean(unlist(onestep.for))
}
rf.var <- function(y){
nrow = nrow(y)
x = matrix(NA,nrow= nrow - 4, ncol= 250)
for(i in 1:(nrow-4)){
x[i,] <- as.vector(unlist(y[i:(i+4),]))
}
t = na.omit(shift(y$TARGET,5,type="lead"))
nrowx = nrow(x)
row.names(x) <- 1:nrowx
rf <- randomForest(x =x[-nrowx,],y = t,xtest= matrix(x[nrowx,],nrow = 1),
importance=TRUE)
coln <- unique(c(1,ceiling(as.numeric(names(sort(rf$importance[,2],decreasing = TRUE)))/5)[1:15]))
print(coln)
pred <- rf$test$predicted
}
rf.model <- function(y){
coln = c(1,4,5,11,13,16,21,24,27,28,35,38,40,41,46)
y = y[,coln]
nrow = nrow(y)
lag = 1
x = matrix(NA,nrow= nrow - lag, ncol= 15*(lag+1))
for(i in 1:(nrow-lag)){
x[i,] <- as.vector(unlist(y[i:(i+lag),]))
}
t = na.omit(shift(y$TARGET,lag+1,type="lead"))
nrowx = nrow(x)
row.names(x) <- 1:nrowx
rf <- randomForest(x =x[-nrowx,],y = t, xtest= matrix(x[nrowx,],nrow = 1), ntree = 50, nodesize = 1)
pred <- rf$test$predicted
}
gbm.model <- function(y){
coln = c(1,4,5,11,13,16,21,24,27,28,35,38,40,41,46)
y = y[,coln]
nrow = nrow(y)
lag = 1
x = matrix(NA,nrow= nrow - lag, ncol= 15*(lag+1))
for(i in 1:(nrow-lag)){
x[i,] <- as.vector(unlist(y[i:(i+lag),]))
}
t = na.omit(shift(y$TARGET,lag+1,type="lead"))
nrowx = nrow(x)
row.names(x) <- 1:nrowx
xtest= matrix(x[nrowx,],nrow = 1)
fit <- gbm.fit(x=x[-nrowx,], y = t, distribution = "gaussian")
f.predict <- predict(fit,xtest,100)
}
onestp <- function(y){
require(randomForest)
coln = c(1,4,5,11,13,16,21,24,27,28,35,38,40,41,46)
y = y[,coln]
nrow = nrow(y)
lag = 1
x = matrix(NA,nrow= nrow - lag, ncol= 15*(lag+1))
for(i in 1:(nrow-lag)){
x[i,] <- as.vector(unlist(y[i:(i+lag),]))
}
t = na.omit(shift(y$TARGET,lag+1,type="lead"))
nrowx = nrow(x)
row.names(x) <- 1:nrowx
rf <- randomForest(x =x[-nrowx,],y = t, xtest= matrix(x[nrowx,],nrow = 1), ntree = 50, nodesize = 1)
pred <- rf$test$predicted
}
install.packages("data.table")
?shift
remove.package(data.table)
remove.packages(data.table)
remove.packages("data.table")
install.packages("data.table", repos = "https://Rdatatable.github.io/data.table", type = "source")
library(data.table)
setwd("~/Desktop/BGSE/AdvancedCompMethods/Project/predicting-online-news-popularity/code")
data <- read.csv("../data/training70.csv", header = TRUE)
X <- data[,4:62]
popularity <- data[,63]
combined <- cbind(X, popularity)
combined$popularity <- as.factor(combined$popularity)
features <- names(X)
data <- read.csv("../data/test30.csv", header = TRUE)
X_test <- data[,4:62]
varType <- rep( NA, length(X) )
for ( i in 1:length(X) ) {
type <- class( X[,i] )
if (type=="int") {
if (length(unique(X[,i])) > 2) {
varType[i] <- "count"
} else {
varType[i] <- "binary"
}
} else {
varType[i] <- type
}
}
table(varType)
head(names(X))
tail(names(X))
?apply
apply(X,2,class)
library(testthat)
?multinom
load("~/Desktop/BGSE/AdvancedCompMethods/Project/RF.H2o.RData")
library(h2o)
h2o.init(nthreads = -1)
path1 <- "Transformed_Train.csv"
training.hex <- h2o.uploadFile(path = path1, destination_frame = "training.hex", sep=",")
setwd("~/Desktop/BGSE/AdvancedCompMethods/Project/Data - too large for git/")
training.hex <- h2o.uploadFile(path = path1, destination_frame = "training.hex", sep=",")
dim(training.hex)
setwd("~/Desktop/BGSE/AdvancedCompMethods/Project/predicting-online-news-popularity/Report")
setwd("~/Desktop/BGSE/AdvancedCompMethods/Project/predicting-online-news-popularity/Report")
library(png)
install.packages("png")
contInt <- function(train, test) {
train       <- train[,3:62]
X_train     <- train[,1:59]
Y_train     <- factor(train[,60])
test        <- test[,3:61]
X_test      <- test
# discover class of each feature - "numeric" or "integer"
varType     <- rep( NA, length(X_train) )
for ( i in 1:length(X_train) ) {
varType[i] <- class( X_train[,i] )
}
# subset training and test sets for continuous variables
X_train_cont    <- X_train[,(varType=="numeric")]
X_test_cont     <- X_test[ ,(varType=="numeric")]
# define a vector consisting of the names of the continuous variables
features_cont   <- names(X_train_cont)
p_cont  <- ncol(X_test_cont)
# ANOVA - Check whether the means of all possible first order interaction terms are
# significantly different. ie whether they exhibit power in separating the classes.
term1 <- vector()
term2 <- vector()
interactions_train <- vector()
interactions_test  <- vector()
for ( i in 1:p_cont ) {
if (i<p_cont) {
for ( j in (i+1):p_cont ) {
# construct potential interaction term
interact_train <- X_train_cont[,i]*X_train_cont[,j]
# run ANOVA for potential interaction term regressed on the labels
XX_anov <- aov( interact_train ~ Y_train )
# calculate TukeyHSD to determine which means are significantly different
# if all (10) means are statistically significantly different at 5% level, accept the interaction variable
if (sum( TukeyHSD(XX_anov)[[1]][,4] < 0.05 ) == 10) {     # if null is NOT accepted if (p-value < 0.05) (ie means are not equal at significance level 5%),
term1 <- c(term1, features_cont[i])
term2 <- c(term2, features_cont[j])
# add interaction term to data frame - training set
interactions_train <- data.frame(cbind(interact_train, interactions_train))
# add same interaction term for test set
interact_test <- X_test_cont[,i]*X_test_cont[,j]
interactions_test <- data.frame(cbind(interact_test, interactions_test))
}
}
}
}
list(train=interactions_train, test=interactions_test)
}
setwd("~/Desktop/BGSE/AdvancedCompMethods/Project/predicting-online-news-popularity/Data")
train       <- read.csv("../data/news_popularity_training.csv", header = TRUE)
test        <- read.csv("../data/news_popularity_test.csv", header = TRUE)
output <- contInt(train, test)
dim(output$train)
dim(output$test)
names(output$train)
