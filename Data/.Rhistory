bias <- coef(datafit1)[1]
intercept1 <- (-bias + 0.5)/weights["PIratio"]
slope1 <- -(weights["solvency"]/weights["PIratio"])
bound1<-c(intercept1,slope1)
#Plot data with boundaries
pdf('discFunction3C.pdf')
print(ggplot(data = data, aes(x = solvency, y = PIratio, colour=Response, fill=Response)) +
scale_color_manual(values = c("green", "red", "yellow")) +
geom_point(size=3) +
xlab("Solvency") +
ylab("Weight") +
theme_bw() +
geom_abline(intercept = bound[1], slope = bound[2])+
geom_abline(intercept = bound1[1], slope = bound1[2]))
dev.off()
View(data)
## EXERCISE 2:
# DATA
library(mvtnorm)
sigmaXY <- function(rho, sdX, sdY) {
covTerm <- rho * sdX * sdY
VCmatrix <- matrix(c(sdX^2, covTerm, covTerm, sdY^2),
2, 2, byrow = TRUE)
return(VCmatrix)
}
genBVN <- function(n = 1, seed = NA, muXY=c(0,1), sigmaXY=diag(2)) {
if(!is.na(seed)) set.seed(seed)
rdraws <- rmvnorm(n, mean = muXY, sigma = sigmaXY)
return(rdraws)
}
# correlation is slightly negative
sigmaXY(rho=-0.1, sdX=1, sdY=20)
# creating a function for all of this
# create small wrapper functions
sigmaXY <- function(rho, sdX, sdY) {
covTerm <- rho * sdX * sdY
VCmatrix <- matrix(c(sdX^2, covTerm, covTerm, sdY^2),
2, 2, byrow = TRUE)
return(VCmatrix)
}
genBVN <- function(n = 1, seed = NA, muXY=c(0,1), sigmaXY=diag(2)) {
if(!is.na(seed)) set.seed(seed)
rdraws <- rmvnorm(n, mean = muXY, sigma = sigmaXY)
return(rdraws)
}
# creating a function for all of this
loanData <- function(noApproved, noDenied, muApproved, muDenied, sdApproved,
sdDenied, rhoApproved, rhoDenied, seed=1111) {
sigmaApproved <- sigmaXY(rho=rhoApproved, sdX=sdApproved[1], sdY=sdApproved[2])
sigmaDenied <- sigmaXY(rho=rhoDenied, sdX=sdDenied[1], sdY=sdDenied[2])
approved <- genBVN(noApproved, muApproved, sigmaApproved, seed = seed)
denied <- genBVN(noDenied, muDenied, sigmaDenied, seed = seed+1)
loanDf <- as.data.frame(rbind(approved,denied))
deny <- c(rep("Approved", noApproved), rep("Denied", noDenied))
target = c(rep(0, noApproved), rep(1, noDenied))
loanDf <- data.frame(loanDf, deny, target)
colnames(loanDf) <- c("PIratio", "solvency", "Response", "target")
return(loanDf)
}
# generating some data
loanDf <- loanData(noApproved=50, noDenied=50, c(4, 150), c(10, 100),
c(1,20), c(2,30), -0.1, 0.6, 1221)
# NEW CATEGORY: undecided
und.solvency<-seq(75,175,length.out = 50)
und.PI<-seq(3,9,length.out = 50)+rnorm(50,0,1)
new<-cbind(und.PI, und.solvency, rep('Undecided',50), rep(0,50))
colnames(new)<-colnames(loanDf)
data<-rbind(loanDf, new)
data[,c(1,2,4)]<-apply(data[,c(1,2,4)],2,as.numeric)
# Save data
data <- data[,1:3]
data$approved <- predict.lm(datafit1)
data$approved[data$approved >= 0.5] <- 1
data$approved[data$approved < 0.5] <- 0
data$denied <- predict.lm(datafit)
data$denied[data$denied >= 0.5] <- 1
data$denied[data$denied < 0.5] <- 0
data$undecided <- 0
data$undecided[data$approved == 0 & data$denied ==0] <- 1
write.table(data, 'predictions.csv', row.names = FALSE, sep=";")
#target variable for each category
data$target1<-c( rep(1,50), rep(0,100))
# DISCRIMINANT ANALYSIS
#Bound: deny vs other
datafit <- lm(as.numeric(target) ~ solvency + PIratio + 1, data=data)
weights <- coef(datafit)[c("solvency", "PIratio")]
bias <- coef(datafit)[1]
intercept <- (-bias + 0.5)/weights["PIratio"]
slope <- -(weights["solvency"]/weights["PIratio"])
bound<-c(intercept,slope)
#Bound: accepted vs other
datafit1 <- lm(as.numeric(target1) ~ solvency + PIratio + 1, data=data)
weights <- coef(datafit1)[c("solvency", "PIratio")]
bias <- coef(datafit1)[1]
intercept1 <- (-bias + 0.5)/weights["PIratio"]
slope1 <- -(weights["solvency"]/weights["PIratio"])
bound1<-c(intercept1,slope1)
#Plot data with boundaries
pdf('discFunction3C.pdf')
print(ggplot(data = data, aes(x = solvency, y = PIratio, colour=Response, fill=Response)) +
scale_color_manual(values = c("green", "red", "yellow")) +
geom_point(size=3) +
xlab("Solvency") +
ylab("Weight") +
theme_bw() +
geom_abline(intercept = bound[1], slope = bound[2])+
geom_abline(intercept = bound1[1], slope = bound1[2]))
dev.off()
## EXERCISE 2:
# DATA
library(mvtnorm)
sigmaXY <- function(rho, sdX, sdY) {
covTerm <- rho * sdX * sdY
VCmatrix <- matrix(c(sdX^2, covTerm, covTerm, sdY^2),
2, 2, byrow = TRUE)
return(VCmatrix)
}
genBVN <- function(n = 1, seed = NA, muXY=c(0,1), sigmaXY=diag(2)) {
if(!is.na(seed)) set.seed(seed)
rdraws <- rmvnorm(n, mean = muXY, sigma = sigmaXY)
return(rdraws)
}
# correlation is slightly negative
sigmaXY(rho=-0.1, sdX=1, sdY=20)
# creating a function for all of this
# create small wrapper functions
sigmaXY <- function(rho, sdX, sdY) {
covTerm <- rho * sdX * sdY
VCmatrix <- matrix(c(sdX^2, covTerm, covTerm, sdY^2),
2, 2, byrow = TRUE)
return(VCmatrix)
}
genBVN <- function(n = 1, seed = NA, muXY=c(0,1), sigmaXY=diag(2)) {
if(!is.na(seed)) set.seed(seed)
rdraws <- rmvnorm(n, mean = muXY, sigma = sigmaXY)
return(rdraws)
}
# creating a function for all of this
loanData <- function(noApproved, noDenied, muApproved, muDenied, sdApproved,
sdDenied, rhoApproved, rhoDenied, seed=1111) {
sigmaApproved <- sigmaXY(rho=rhoApproved, sdX=sdApproved[1], sdY=sdApproved[2])
sigmaDenied <- sigmaXY(rho=rhoDenied, sdX=sdDenied[1], sdY=sdDenied[2])
approved <- genBVN(noApproved, muApproved, sigmaApproved, seed = seed)
denied <- genBVN(noDenied, muDenied, sigmaDenied, seed = seed+1)
loanDf <- as.data.frame(rbind(approved,denied))
deny <- c(rep("Approved", noApproved), rep("Denied", noDenied))
target = c(rep(0, noApproved), rep(1, noDenied))
loanDf <- data.frame(loanDf, deny, target)
colnames(loanDf) <- c("PIratio", "solvency", "deny", "target")
return(loanDf)
}
# generating some data
loanDf <- loanData(noApproved=50, noDenied=50, c(4, 150), c(10, 100),
c(1,20), c(2,30), -0.1, 0.6, 1221)
# NEW CATEGORY: undecided
und.solvency<-seq(80,160,length.out = 50)
und.PI<-seq(4,9,length.out = 50)+rnorm(50,0,1)
new<-cbind(und.PI, und.solvency, rep('Undecided',50), rep(0,50))
colnames(new)<-colnames(loanDf)
data<-rbind(loanDf, new)
data[,c(1,2,4)]<-apply(data[,c(1,2,4)],2,as.numeric)
# Save data
data <- data[,1:3]
data$approved <- predict.lm(datafit1)
data$approved[data$approved >= 0.5] <- 1
data$approved[data$approved < 0.5] <- 0
data$denied <- predict.lm(datafit)
data$denied[data$denied >= 0.5] <- 1
data$denied[data$denied < 0.5] <- 0
data$undecided <- 0
data$undecided[data$approved == 0 & data$denied ==0] <- 1
write.table(data, 'predictions.csv', row.names = FALSE, sep=";")
#target variable for each category
data$target1<-c( rep(1,50), rep(0,100))
data$target2<-c( rep(0,100), rep(1,50))
# DISCRIMINANT ANALYSIS
#Bound: deny vs other
datafit <- lm(as.numeric(target) ~ solvency + PIratio + 1, data=data)
weights <- coef(datafit)[c("solvency", "PIratio")]
bias <- coef(datafit)[1]
intercept <- (-bias + 0.5)/weights["PIratio"]
slope <- -(weights["solvency"]/weights["PIratio"])
bound<-c(intercept,slope)
#Bound: accepted vs other
datafit1 <- lm(as.numeric(target1) ~ solvency + PIratio + 1, data=data)
weights <- coef(datafit1)[c("solvency", "PIratio")]
bias <- coef(datafit1)[1]
intercept <- (-bias + 0.5)/weights["PIratio"]
slope <- -(weights["solvency"]/weights["PIratio"])
bound1<-c(intercept,slope)
#Plot data with boundaries
pdf('discFunction3C.pdf')
ggplot(data = data, aes(x = solvency, y = PIratio, colour=deny, fill=deny)) +
geom_point(size=3) +
xlab("Solvency") +
ylab("Weight") +
theme_bw() +
geom_abline(intercept = bound[1], slope = bound[2])+
geom_abline(intercept = bound1[1], slope = bound1[2])
dev.off()
#EXERCISE 1
library(ggplot2)
genData<-function(obs0=100, obs1=100, variance= 0.01, save.data=FALSE, save.plot=FALSE){
# Generating data
num<-seq(-1,1,length.out = obs1)
x1<-sin(num)
y1<-cos(num)+rnorm(obs1, 0, variance)
x0<-seq(-1,1,length.out = obs0)
y0<-seq(0.6,1,length.out = obs0)+rnorm(obs0,0,variance)
x<-c(x0,x1)
y<-c(y0,y1)
target<-c(rep(0,obs0), rep(1,obs1))
data<-data.frame(x=x,y=y,target=target)
data$target<-as.factor(data$target)
# Save data
if(save.data==TRUE){
write.table(data, 'dataset.csv', row.names = FALSE, sep=";")
}
# Create plot
if(save.plot==TRUE){
pdf(file='dataPlot.pdf')
ggplot(data = data, aes(x = x, y = y, colour=target, fill=target)) +
geom_point(size=3) +
theme_bw()
dev.off()
}
return(data)
}
genData(200,200,0.01, save.data = TRUE, save.plot = TRUE)
## EXERCISE 2:
# DATA
library(mvtnorm)
sigmaXY <- function(rho, sdX, sdY) {
covTerm <- rho * sdX * sdY
VCmatrix <- matrix(c(sdX^2, covTerm, covTerm, sdY^2),
2, 2, byrow = TRUE)
return(VCmatrix)
}
genBVN <- function(n = 1, seed = NA, muXY=c(0,1), sigmaXY=diag(2)) {
if(!is.na(seed)) set.seed(seed)
rdraws <- rmvnorm(n, mean = muXY, sigma = sigmaXY)
return(rdraws)
}
# correlation is slightly negative
sigmaXY(rho=-0.1, sdX=1, sdY=20)
# creating a function for all of this
# create small wrapper functions
sigmaXY <- function(rho, sdX, sdY) {
covTerm <- rho * sdX * sdY
VCmatrix <- matrix(c(sdX^2, covTerm, covTerm, sdY^2),
2, 2, byrow = TRUE)
return(VCmatrix)
}
genBVN <- function(n = 1, seed = NA, muXY=c(0,1), sigmaXY=diag(2)) {
if(!is.na(seed)) set.seed(seed)
rdraws <- rmvnorm(n, mean = muXY, sigma = sigmaXY)
return(rdraws)
}
# creating a function for all of this
loanData <- function(noApproved, noDenied, muApproved, muDenied, sdApproved,
sdDenied, rhoApproved, rhoDenied, seed=1111) {
sigmaApproved <- sigmaXY(rho=rhoApproved, sdX=sdApproved[1], sdY=sdApproved[2])
sigmaDenied <- sigmaXY(rho=rhoDenied, sdX=sdDenied[1], sdY=sdDenied[2])
approved <- genBVN(noApproved, muApproved, sigmaApproved, seed = seed)
denied <- genBVN(noDenied, muDenied, sigmaDenied, seed = seed+1)
loanDf <- as.data.frame(rbind(approved,denied))
deny <- c(rep("Approved", noApproved), rep("Denied", noDenied))
target = c(rep(0, noApproved), rep(1, noDenied))
loanDf <- data.frame(loanDf, deny, target)
colnames(loanDf) <- c("PIratio", "solvency", "Response", "target")
return(loanDf)
}
# generating some data
loanDf <- loanData(noApproved=50, noDenied=50, c(4, 150), c(10, 100),
c(1,20), c(2,30), -0.1, 0.6, 1221)
# NEW CATEGORY: undecided
und.solvency<-seq(75,175,length.out = 50)
und.PI<-seq(3,9,length.out = 50)+rnorm(50,0,1)
new<-cbind(und.PI, und.solvency, rep('Undecided',50), rep(0,50))
colnames(new)<-colnames(loanDf)
data<-rbind(loanDf, new)
data[,c(1,2,4)]<-apply(data[,c(1,2,4)],2,as.numeric)
#target variable for each category
data$target1<-c( rep(1,50), rep(0,100))
# DISCRIMINANT ANALYSIS
#Bound: deny vs other
datafit <- lm(as.numeric(target) ~ solvency + PIratio + 1, data=data)
weights <- coef(datafit)[c("solvency", "PIratio")]
bias <- coef(datafit)[1]
intercept <- (-bias + 0.5)/weights["PIratio"]
slope <- -(weights["solvency"]/weights["PIratio"])
bound<-c(intercept,slope)
#Bound: accepted vs other
datafit1 <- lm(as.numeric(target1) ~ solvency + PIratio + 1, data=data)
weights <- coef(datafit1)[c("solvency", "PIratio")]
bias <- coef(datafit1)[1]
intercept1 <- (-bias + 0.5)/weights["PIratio"]
slope1 <- -(weights["solvency"]/weights["PIratio"])
bound1<-c(intercept1,slope1)
# Save data
data <- data[,1:3]
data$approved <- predict.lm(datafit1)
data$approved[data$approved >= 0.5] <- 1
data$approved[data$approved < 0.5] <- 0
data$denied <- predict.lm(datafit)
data$denied[data$denied >= 0.5] <- 1
data$denied[data$denied < 0.5] <- 0
data$undecided <- 0
data$undecided[data$approved == 0 & data$denied ==0] <- 1
write.table(data, 'predictions.csv', row.names = FALSE, sep=";")
#Plot data with boundaries
pdf('discFunction3C.pdf')
print(ggplot(data = data, aes(x = solvency, y = PIratio, colour=Response, fill=Response)) +
scale_color_manual(values = c("green", "red", "yellow")) +
geom_point(size=3) +
xlab("Solvency") +
ylab("Weight") +
theme_bw() +
geom_abline(intercept = bound[1], slope = bound[2])+
geom_abline(intercept = bound1[1], slope = bound1[2]))
dev.off()
View(data)
chooseCRANmirror()
install.packages("ggplot")
genStickSnake <- function(noStick=100, noSnake=100,
min=0, max=100,
gradient=1, amplitude=0.2, wavelength=500,
saveData=TRUE,
savePlot=TRUE) {
#min, max and gradient are variables for both the stick and the snake
#amplitude and wavelength are only for the snake
#Be careful, because if you change the range, amplitude or wavelength,
#the data sets can easily become ugly.
#calculating the stick
x <- runif(noStick, min, max)
y <- gradient*x + rnorm(noStick)
stick <- data.frame(x, y)
#calculating the snake
x <- runif(noSnake, min, max)
y <- gradient*x + rnorm(noSnake) + (max-min)*amplitude*sin((max-min)/wavelength*x)
snake <- data.frame(x, y)
#joining the stick and the snake
sas <- rbind(stick, snake)
stick_or_snake <- c(rep("stick", noStick), rep("snake", noSnake))
target <- c(rep(0, noStick), rep(1, noSnake))
sas <- data.frame(sas, target, stick_or_snake)
names(sas) <- c("x1", "x2", "y", "label")
if(saveData){
write.csv(sas, "dataset.csv", row.names = FALSE)
}
if(savePlot){
plot <- ggplot2(data = sas, aes(x=x1, y=x2, color=label)) +
geom_point() +
theme_bw()
cairo_pdf("dataPlot.pdf")
print(plot)
dev.off()
}
return(sas)
}
genStickSnake(noStick = 100, noSnake = 100)
library(ggplot2)
genStickSnake(noStick = 100, noSnake = 100)
genStickSnake <- function(noStick=100, noSnake=100,
min=0, max=100,
gradient=1, amplitude=0.2, wavelength=500,
saveData=TRUE,
savePlot=TRUE) {
#min, max and gradient are variables for both the stick and the snake
#amplitude and wavelength are only for the snake
#Be careful, because if you change the range, amplitude or wavelength,
#the data sets can easily become ugly.
#calculating the stick
x <- runif(noStick, min, max)
y <- gradient*x + rnorm(noStick)
stick <- data.frame(x, y)
#calculating the snake
x <- runif(noSnake, min, max)
y <- gradient*x + rnorm(noSnake) + (max-min)*amplitude*sin((max-min)/wavelength*x)
snake <- data.frame(x, y)
#joining the stick and the snake
sas <- rbind(stick, snake)
stick_or_snake <- c(rep("stick", noStick), rep("snake", noSnake))
target <- c(rep(0, noStick), rep(1, noSnake))
sas <- data.frame(sas, target, stick_or_snake)
names(sas) <- c("x1", "x2", "y", "label")}
genStickSnake()
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
kNN <- function(features, labels, memory = NULL,
k = 1, p = 2, type="train",norm = TRUE) {
library(assertthat)
library(flexclust)
# test the inputs
not_empty(features); not_empty(labels);
is.string(type); assert_that(type %in% c("train", "predict"))
if (type == "train") {
assert_that(nrow(features) == length(labels))
}else if (type == "predict") {
assert_that(nrow(features) == length(labels) &
not_empty(memory) &
ncol(memory) == ncol(features) )
}
is.count(k); assert_that(k <= nrow(features))
if(p != Inf)is.count(p);
if(norm == TRUE) features <- as.data.frame(lapply(features, normalize))
method <- ifelse(p==1, 'manhattan', ifelse(p==2,'euclidean',ifelse(p == Inf,'maximum','minkowski')))
if (type == "train") {
noObs <- nrow(features)
distMatrix <- as.matrix(dist(features,method = method,p=p))
} else if (type == "predict") {
noObs <- nrow(memory)
if(norm == TRUE) memory <- as.data.frame(lapply(memory, normalize))
distMatrix <- as.matrix(dist2(features,memory,method = method,p=p))
}
# Sort the distances in increasing numerical order and pick the first
# k elements
neighbors <- apply(distMatrix, 2, order)
# Compute and return the most frequent class in the k nearest neighbors
predLabels <- rep(NA, noObs)
prob <- rep(NA, noObs)
for (obs in 1:noObs) {
predLabels[obs] <- as.numeric(names(tail(sort(table(labels[neighbors[1:k, obs]])),1)))
prob[obs] <- round(tail(sort(table(labels[neighbors[1:k, obs]])),1)/k,4)
}
# examine the performance, available only if training
if (type == "train") {
errorCount <- table(predLabels, labels)
accuracy <- mean(predLabels == labels)
} else if (type == "predict") {
errorCount <- NA
accuracy <- NA
}
# return the results
return(list(predLabels = predLabels,
prob = prob,
accuracy = accuracy,
errorCount = errorCount))
}
genStickSnake <- function(noStick=100, noSnake=100,
min=0, max=100,
gradient=1, amplitude=0.2, wavelength=500,
saveData=TRUE,
savePlot=TRUE) {
#min, max and gradient are variables for both the stick and the snake
#amplitude and wavelength are only for the snake
#Be careful, because if you change the range, amplitude or wavelength,
#the data sets can easily become ugly.
#calculating the stick
x <- runif(noStick, min, max)
y <- gradient*x + rnorm(noStick)
stick <- data.frame(x, y)
#calculating the snake
x <- runif(noSnake, min, max)
y <- gradient*x + rnorm(noSnake) + (max-min)*amplitude*sin((max-min)/wavelength*x)
snake <- data.frame(x, y)
#joining the stick and the snake
sas <- rbind(stick, snake)
stick_or_snake <- c(rep("stick", noStick), rep("snake", noSnake))
target <- c(rep(0, noStick), rep(1, noSnake))
sas <- data.frame(sas, target, stick_or_snake)
names(sas) <- c("x1", "x2", "y", "label")}
dataset <- genStickSnake()
features <- dataset[,c(1,2)]
labels <- dataset$y
result <- kNN(features,labels,k = 5, p = 2, type = "train")
predictions <- data.frame(cbind(dataset,predLabels = result$predLabels,prob= result$prob))
colnames(predictions) <- c("Dimension1","Dimension2","ClassLabel","PredictedLabel","Prob")
predictions$ClassLabel <- factor(predictions$ClassLabel)
# save the data in CSV format
write.csv(predictions, file="predictions.csv", row.names = FALSE)
test <- data.frame(cbind(rep(seq(min(predictions$Dimension1), max(predictions$Dimension1), length.out=20),20)
,rep(seq(min(predictions$Dimension2), max(predictions$Dimension2), length.out=20),each=20)))
dataPred <- kNN(features,labels,test,k = 5, p = 2, type = "predict")
dataPred$prob[dataPred$predLabels == 1] <- dataPred$prob[dataPred$predLabels == 1]
dataPred$prob[dataPred$predLabels == 0] <- 1 - dataPred$prob[dataPred$predLabels == 0]
df<-data.frame(cbind(test,z = dataPred$prob))
library(ggplot2)
dataPlot <- ggplot(predictions, aes(x=Dimension1, y=Dimension2) ) +
geom_point(size = 3, aes(colour = ClassLabel)) +
geom_contour(data=df, aes(x=X1, y=X2, z=z),breaks = 0.5)
dataPlot
# saving
cairo_pdf("dataPlot.pdf")
print(dataPlot)
dev.off()
#############################################################################################
installed.packages(assertthat)
installed.packages("assertthat")
installed.packages("flexclust")
installed.packages(flexclust)
install.packages(flexclust)
install.packages("flexclust")
install.packages("assertthat")
install.packages("ggplot")
chooseCRANmirror()
install.packages("assertthat")
install.packages("assertthat")
setwd("~/Escritorio/Data Science/2nd term/Adv. Computational Methods/predicting-online-news-popularity/Data")
library(h2o)
library(gbm)
h2o.init(nthreads = -1)
path1 <- "training70.csv"
path2 <- "test30.csv"
training.hex <- h2o.uploadFile(path = path1, destination_frame = "training.hex" )
test.hex <- h2o.uploadFile(path = path2, destination_frame = "test.hex" )
training.hex$popularity <- as.factor(training.hex$popularity)
training.gbm <- h2o.gbm(y=63, x=5:62, training_frame= training.hex, ntrees=100, max_depth=3, min_rows= 10, learn_rate=0.001, distribution="multinomial")
gbm.perf(training.gbm)
par(ask=T)
gbm.perf(training.gbm)
